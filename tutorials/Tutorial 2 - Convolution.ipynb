{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "from skimage.util.shape import view_as_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def almost_equal(vec1, vec2, m_pow_ten):\n",
    "    if len(vec1) != len(vec2):\n",
    "        return False\n",
    "\n",
    "    upper_bound = pow(10, -m_pow_ten)\n",
    "    for v1, v2 in zip(vec1, vec2):\n",
    "        if abs(v1 - v2) > upper_bound:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_strided_im2col(x, kernel):\n",
    "    \"\"\"\n",
    "    Memory strided Image Block to Columns implementation\n",
    "    \"\"\"\n",
    "    # Infer shapes\n",
    "    x_h, x_w = x.shape\n",
    "    k_h, k_w = kernel.shape\n",
    "    # Assuming Padding=0, Stride=1\n",
    "    out_h, out_w = (x.shape[0] - kernel.shape[0] + 1, x.shape[1] - kernel.shape[1] + 1)\n",
    "\n",
    "    windows = view_as_windows(x, kernel.shape)\n",
    "    return windows.reshape(out_h * out_w, k_h * k_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_conv_2d(x, kernel):\n",
    "    return torch.nn.functional.conv2d(\n",
    "        input=x, weight=kernel, stride=1, padding=0, dilation=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckks_conv2d(x, kernel, context):\n",
    "    # for each convolution layer, a communication between the client and server\n",
    "    # is required. The server send the ciphertext (encrypted vector) to the client\n",
    "    # which is the input of the next convolution layer, in order to decrypt it\n",
    "    # and apply im2col (Image Block to Column) on the that input.\n",
    "    new_x = memory_strided_im2col(x, kernel)\n",
    "    print(\"new_x shape: \", new_x.shape)\n",
    "    print(new_x)\n",
    "    \n",
    "    # after that the client encode and encrypt the input matrix in a vertical scan\n",
    "    # (column-major) and send it back to the server.\n",
    "    # new_x.flatten(order='F') is equivalent to new_x.T.flatten()\n",
    "    x_enc = ts.ckks_vector(context, new_x.flatten(order='F').tolist())\n",
    "\n",
    "    rows_number = new_x.shape[0]\n",
    "    kernel_size = len(kernel.flatten().tolist())\n",
    "    print(\"flatten_kernel_size: \", kernel_size)\n",
    "    print(\"rows_number: \", rows_number)\n",
    "    print(\"ckksvector size: \", x_enc.size())\n",
    "    t = time()\n",
    "    x_enc.mat_plain_vec_mult_inplace(kernel.flatten().tolist(), rows_number)\n",
    "    t = time() - t\n",
    "    print(\"time cost:\", t)\n",
    "    return x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (4, 4)\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "kernel (2, 2)\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "new_x shape:  (9, 4)\n",
      "[[ 1  2  5  6]\n",
      " [ 2  3  6  7]\n",
      " [ 3  4  7  8]\n",
      " [ 5  6  9 10]\n",
      " [ 6  7 10 11]\n",
      " [ 7  8 11 12]\n",
      " [ 9 10 13 14]\n",
      " [10 11 14 15]\n",
      " [11 12 15 16]]\n",
      "flatten_kernel_size:  4\n",
      "rows_number:  9\n",
      "ckksvector size:  36\n",
      "time cost: 0.014109134674072266\n",
      "9\n",
      "y_enc\n",
      "[44.000006357476, 54.00000741829126, 64.00000852519227, 84.00001123350282, 94.00001262979303, 104.00001397124595, 124.00001661905705, 134.00001796757925, 144.00001931391517]\n",
      "y_toch\n",
      "[ 44.  54.  64.  84.  94. 104. 124. 134. 144.]\n"
     ]
    }
   ],
   "source": [
    "# input image dimension n * n\n",
    "x_size = 4\n",
    "# kernel dimension n * n\n",
    "k_size = 2\n",
    "\n",
    "# generated incremeneted values: 1, 2, ..., n^2\n",
    "x = np.arange(1, x_size ** 2 + 1).reshape(x_size, x_size)\n",
    "kernel = np.arange(1, k_size ** 2 + 1).reshape(k_size, k_size)\n",
    "\n",
    "# generated random values\n",
    "# x = np.random.rand(x_size, x_size)\n",
    "# kernel = np.random.rand(k_size, k_size)\n",
    "\n",
    "print(\"input\", x.shape)\n",
    "print(x)\n",
    "print(\"kernel\", kernel.shape)\n",
    "print(kernel)\n",
    "\n",
    "\n",
    "# Create TenSEAL context\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    ")\n",
    "# set the scale\n",
    "context.global_scale = pow(2, 40)\n",
    "# generated galois keys in order to do rotation on ciphertext vectors\n",
    "context.generate_galois_keys()\n",
    "\n",
    "\n",
    "y_enc = ckks_conv2d(x, kernel, context)\n",
    "print(y_enc.size())\n",
    "y_plain = y_enc.decrypt()\n",
    "\n",
    "print(\"y_enc\")\n",
    "print(y_plain)\n",
    "\n",
    "\n",
    "y_torch = torch_conv_2d(\n",
    "    torch.from_numpy(x.astype(\"float32\")).unsqueeze(0).unsqueeze(0),\n",
    "    torch.from_numpy(kernel.astype(\"float32\")).unsqueeze(0).unsqueeze(0),\n",
    ")\n",
    "y_torch = y_torch.flatten().numpy()\n",
    "print(\"y_toch\")\n",
    "print(y_torch)\n",
    "\n",
    "assert almost_equal(y_plain, y_torch, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenseal-venv",
   "language": "python",
   "name": "tenseal-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
